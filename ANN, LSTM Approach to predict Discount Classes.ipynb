{
  "cells": [
    {
      "metadata": {
        "_uuid": "9d96eb4dd1cb16e1d04b48a26d6bffa8b0e0aac2"
      },
      "cell_type": "markdown",
      "source": "<font size=\"20\">Discount Prediction</font>"
    },
    {
      "metadata": {
        "_uuid": "e86bb06b8be3861460060e9beca27d37e8cfafbe"
      },
      "cell_type": "markdown",
      "source": "The objective of this \"Discount Prediction\" Competition was to build a model to Predict Medical Wholesales Discount to their customers. In this notebook, we will walk through a complete machine learning solution, try out two deep learning models, select a model and , inspect the outputs of the model and draw conclusions. We would like to thank everyone for this hackathon."
    },
    {
      "metadata": {
        "_uuid": "0b15c4242ef5eab0176483c2d262610716a26916"
      },
      "cell_type": "markdown",
      "source": "<h1>Importing the Libraries</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9d91f358a8cad0a5681c0de601005fae513dc1a"
      },
      "cell_type": "code",
      "source": "import pandas as pd #Data Analysis\nimport numpy as np #Linear Algebra\nimport seaborn as sns #Data Visualization\nimport matplotlib.pyplot as plt #Data Visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ab8b102514788aff0fa37a37f22c27df669fb6e"
      },
      "cell_type": "code",
      "source": "import os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "60963ac9c166fd8a94082d8fd025bc03ca9d2db6"
      },
      "cell_type": "markdown",
      "source": "<h1>Importing the datasets</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e54c1755c0a748b84ef67cab2a6e3bf4af6c681a"
      },
      "cell_type": "code",
      "source": "#This is the Product_sales_train_and_test dataset but without the \"[]\" in the Customer Basket.\ndf1=pd.read_csv(\"../input/remove/data.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2be3a39d9ff439268abcee3c87c2ba780bcf73dd"
      },
      "cell_type": "code",
      "source": "df2=pd.read_csv(\"../input/discount-prediction/Train.csv\")\ndf3=pd.read_csv(\"../input/discount-prediction/test.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4415180cc3da540cf79df87455819478752260e"
      },
      "cell_type": "code",
      "source": "df1.fillna(float(0.0),inplace=True)\ndf2.fillna(float(0.0),inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1438a604b74489023d612cdf7ffb52faa7602647"
      },
      "cell_type": "markdown",
      "source": "Since to differentiate the Customer Basket is an NLP Problem we will be using CountVectoriser. It converts a collection of text documents to a matrix of token counts. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bc064c1d2ad45a3647fe88ae7b766c12d0ec0c9"
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\ncv1 = CountVectorizer(max_features=500)\ny = cv1.fit_transform(df1[\"Customer_Basket\"]).toarray()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6f7cd0808a08c6f0b30b75f5039237695eb10c1"
      },
      "cell_type": "code",
      "source": "thirty= list(y)\nthirty1=pd.DataFrame(thirty)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51e1932e5471133b1b94b78eddfcff65276d59ab"
      },
      "cell_type": "code",
      "source": "final=pd.concat([df1,thirty1],axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "441393c5c6a7bbe489710edcff366a275fb5b6db"
      },
      "cell_type": "code",
      "source": "df2=df2[df2[\"BillNo\"]!=float(0.0)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf73c4a22608a6d604900d49a6388c8ad7f17deb"
      },
      "cell_type": "code",
      "source": "finaltrain=pd.merge(final,df2,on=\"BillNo\",how=\"inner\")\nfinaltest=pd.merge(final,df3,on=\"BillNo\",how=\"inner\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f40eb35b12c3bbf5a558552be6d083283564dfc"
      },
      "cell_type": "code",
      "source": "finaltrain.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)\nfinaltest.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83c80ae43eeb038854c4adb55ce64b08d0863160"
      },
      "cell_type": "code",
      "source": "X=finaltrain.drop([\"Discount 5%\",\"Discount 12%\",\"Discount 18%\",\"Discount 28%\"],axis=1)\ny=finaltrain[[\"Discount 5%\",\"Discount 12%\",\"Discount 18%\",\"Discount 28%\"]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "484bea530606db6018fe1fcec82fb24f4eb9ddf9"
      },
      "cell_type": "code",
      "source": "X1, y2 = np.array(X), np.array(y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "056c095509fba957ed6dfc17ab52f26ea7d47a8f"
      },
      "cell_type": "code",
      "source": "var = np.reshape(X1, (X1.shape[0], X1.shape[1], 1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "58a80e4ba09fa81f005ef33df210e7ce412f6d0f"
      },
      "cell_type": "markdown",
      "source": "<h1>Modeling</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ba60056bea5131d4faa274673feffddc7a6ce2e"
      },
      "cell_type": "code",
      "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "48b50b016da78e1270e572c0529b4f015a377d91"
      },
      "cell_type": "markdown",
      "source": "<h1>1. Artificial Neural Networks (ANN)</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5565991bd01406ee1b82a7df27bd54a40505e215"
      },
      "cell_type": "code",
      "source": "# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 500))\nclassifier.add(Dropout(0.2))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units =32 , kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units =16 , kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dropout(0.2))\n\n# Adding the output layer\nclassifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'softmax'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X, y, batch_size = 10, epochs = 50)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c7e688432f00445ac1acd9e882e8ecc56710dff"
      },
      "cell_type": "code",
      "source": "annpredictions=classifier.predict(finaltest)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b91ae19e9075bae8a5748d38e7355964e0d1df1"
      },
      "cell_type": "code",
      "source": "discountann=list(annpredictions)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60a07a811f118de9d17ff9611c9a8accb28f6512"
      },
      "cell_type": "code",
      "source": "abbasann=pd.DataFrame(discountann)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "459ca21f2667eb29e221a5c624847ff47c701b18"
      },
      "cell_type": "code",
      "source": "abbasann=(abbasann> 0.4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0081905ffb282e2e77934513b96d51d6422f8b19"
      },
      "cell_type": "markdown",
      "source": "<h1>2. LSTM</h1><br>\nFirst we used ANN but the results were poor and as seen ini our previous kernel we could not see any Customer getting preference for Discounts. Therefore we tried to capture the pattern of discounts been given using an LSTM approach."
    },
    {
      "metadata": {
        "_uuid": "b7bd46ee0a928b2021b514ed3a6333232106f764"
      },
      "cell_type": "markdown",
      "source": "Importing the necessary libraries for an LSTM model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "219d4fc164f9176c1072d571489c387cf7f59a84"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48069c92dc0322d51d7952605ad136dce753b26d"
      },
      "cell_type": "code",
      "source": "# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (var.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units=4, activation='softmax'))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n\n# Fitting the RNN to the Training set\nregressor.fit(var, y2, epochs = 1, batch_size = 32)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1130557f2bf9fa5ca10156129f9baa7f7bafa76b"
      },
      "cell_type": "markdown",
      "source": "We have purposely set the epoch time to 1 as it takes a long time for the kernel to commit."
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "91de555526640313a438eb23df99b132a91308fd"
      },
      "cell_type": "code",
      "source": "finaltest1=np.array(finaltest)\nbaas=np.reshape(finaltest1, (finaltest1.shape[0], finaltest1.shape[1], 1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "0aacf3e49a992822c614a9b50e5d7208296edb44"
      },
      "cell_type": "code",
      "source": "discountclass=regressor.predict(baas)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "aff6230c7436dbbbbd2bfb053ef319d9a34c15df"
      },
      "cell_type": "code",
      "source": "discountbaas=list(discountclass)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "23777b7de36f91189ecc140dae1bc23f8a276a17"
      },
      "cell_type": "code",
      "source": "abbas=pd.DataFrame(discountbaas)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "7ee779796d2849423f2f42c9d880334c18898264"
      },
      "cell_type": "code",
      "source": "abbas= (abbas > 0.3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "9907b74933373aa00e45e7db7a77a714cadd6a16"
      },
      "cell_type": "markdown",
      "source": "<h1>Result</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "818923d3b83c41dbca4d3a23490a18c6facadf6c"
      },
      "cell_type": "markdown",
      "source": "At the end we were able to discern that an <b>LSTM</b> gave us the best result. One major change that we noticed was that the Bill Numbers were change from ZA's to A's from July 1st, 2017 and that in this transition the majority of Discounts also drastically changed from 28% to 12%."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}