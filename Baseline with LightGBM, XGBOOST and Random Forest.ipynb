{
  "cells": [
    {
      "metadata": {
        "_uuid": "db33df87d89c269918f58337be9dfddf49c7e670"
      },
      "cell_type": "markdown",
      "source": "<font size=\"20\">Discount Prediction</font>"
    },
    {
      "metadata": {
        "_uuid": "f45cfae0856d33b92775542676c91f210959a88f"
      },
      "cell_type": "markdown",
      "source": "The objective of this \"Discount Prediction\" Competition was to build a machine learning model to Predict Medical Wholesales Discount to their customers. In this notebook, we will walk through a complete machine learning solution, try out multiple machine learning models, select a model, work to optimize the model, and finally, inspect the outputs of the model and draw conclusions. We would like to thank everyone for this hackathon.<br><br>\nThis notebook is majorly divided into three two parts.They are:\n<ol>\n<li>Exploratory Data Analysis and Preprocessing</li>\n<li>Modeling</li><ul>\n<li><b>LightGBM<b></li>\n<li>XGBOOST</li>\n<li>Random Forest</li>"
    },
    {
      "metadata": {
        "_uuid": "cf030695119e01fea9f0bafca6b9cc35455890b1"
      },
      "cell_type": "markdown",
      "source": "<h1>Importing the Libraries</h1>"
    },
    {
      "metadata": {
        "_uuid": "2fb693b979d611d778a0ce824c5984a413cd47bd"
      },
      "cell_type": "markdown",
      "source": "![](http://)We are gonna start of by importing the generic packages that everyone uses in their kernels."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6792c6e6c70489b2756dad57b606fa856ec17577"
      },
      "cell_type": "code",
      "source": "import pandas as pd #Data Analysis\nimport numpy as np #Linear Algebra\nimport seaborn as sns #Data Visualization\nimport matplotlib.pyplot as plt #Data Visualization\\\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9bf9c631e1beba48a0d8a3e4b36310391383b015"
      },
      "cell_type": "markdown",
      "source": "These are import statements for plotply which is also a visualization library."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ceaef8b5a138120b468e57b59716836c6f8d9c4"
      },
      "cell_type": "code",
      "source": "import json\nimport string\nfrom pandas.io.json import json_normalize\ncolor = sns.color_palette()\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b372ba979943fd8a69c1b36cd7fc22f4a9bd573f"
      },
      "cell_type": "code",
      "source": "import os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0943ee71d92aa48de87250e9a23ea87922402112"
      },
      "cell_type": "markdown",
      "source": "<h1>Importing the datasets</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de374c72c7d967a4587a5d2c56a3e048da775a99"
      },
      "cell_type": "code",
      "source": "#This is the Product_sales_train_and_test dataset but without the \"[]\" in the Customer Basket.\ndf=pd.read_csv(\"../input/removed//data.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0aa81fc2ac9a023a88eb48e0b34fe135ec581b16"
      },
      "cell_type": "code",
      "source": "train=pd.read_csv(\"../input/discount-prediction/Train.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64acd974cca0c98ae4883670763abf75b4a26338"
      },
      "cell_type": "code",
      "source": "test=pd.read_csv(\"../input/discount-prediction/test.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29dcf9f3c2caa6c5030b185b9609ff0c0eeefed4"
      },
      "cell_type": "code",
      "source": "product=pd.read_csv(\"../input/discount-prediction/product_details.csv\",encoding=\"mac-roman\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5b1e927d08d85d1b7a77427f6057535b7b98ef8"
      },
      "cell_type": "code",
      "source": "#Removing the front and trailing spaces\ndf['Customer_Basket']=df['Customer_Basket'].str.lstrip()\ndf['Customer_Basket']=df['Customer_Basket'].str.rstrip()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52f4e19f90d0b5074960a6869c929f2b17d52ad9"
      },
      "cell_type": "code",
      "source": "#The count of the number of Product Id's in the Customer Basket\ndf['Length']=df['Customer_Basket'].str.split(' ').apply(len)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "_uuid": "94c5d4176cb27799c6fdc9236f2a8cb0526c4b9d"
      },
      "cell_type": "markdown",
      "source": "<h1>Exploratory Data Analysis with Preprocessing</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07613e93d5265c904620aed76ed77d7f8f7180e8"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a7b4d4dbd7e6a889d390c6e5179c45919d84b89"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7da093d9378566e4976e2118e54a97902366e75"
      },
      "cell_type": "code",
      "source": "#We can see a lot of null values in the train dataset\ntrain.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87679ad2d4ad8f0a32aced22403a395771ed2c20"
      },
      "cell_type": "code",
      "source": "#Let us see number of null values there are\ntrain.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe1a0cc7eddcdf18af7223a30cb714c881faeee"
      },
      "cell_type": "code",
      "source": "test.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "46295c026b936c3eedcd656a4e6ded466fbaa51d"
      },
      "cell_type": "markdown",
      "source": "No Null Values in the test dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c278fad227898ec9da6d70d5ca593ae80c4fc015"
      },
      "cell_type": "code",
      "source": "train[train['BillNo'].isna()].head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15bb55bc88fcbb5d18ba3d8d5333deeec3552ac5"
      },
      "cell_type": "markdown",
      "source": "From this we can tell that there are null values for the entire row present in the train dataset. The below code is to drop the entire row only when the entire row are \"NaN\" or null values."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe99154b61d86b1c16d4b69297f2e406805f103b"
      },
      "cell_type": "code",
      "source": "train.dropna(axis=0,how='all',inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94193cda45f11edbc76f9e982c082c7d6e5ce177"
      },
      "cell_type": "code",
      "source": "train.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "892062af5a452fa2ef06c0627d3091c5843f83ad"
      },
      "cell_type": "markdown",
      "source": "Now we can see that the majority of the null values are present in the Target variables. But we can impute these values with 0."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a9fb892f6c65130f8d53f252cc81cea9a3aa28d"
      },
      "cell_type": "code",
      "source": "train.fillna(float(0.0),inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20d0efcea647eeb31d9392ae4e4f550ddc16d5ec"
      },
      "cell_type": "code",
      "source": "train.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f11345216c49c4b740d957a7a8c9e1b3bf5409b"
      },
      "cell_type": "markdown",
      "source": "Finally we have no more null values.<br>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26e0a9fb3d11faeb8fae7560e5252961a920eb38"
      },
      "cell_type": "code",
      "source": "train['Customer'].value_counts().head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8cf4335397df882569e84dbdb2ff0faebe34d00c"
      },
      "cell_type": "code",
      "source": "len(set(test['Customer']).difference(set(train['Customer'])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7a7c1fc8a91fc9cf06e543efba37eae44221b17"
      },
      "cell_type": "code",
      "source": "train['Discount 5%'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e3118d3d5acd7c398127ced2815775d3aeea377"
      },
      "cell_type": "markdown",
      "source": "We can see that the classes are highly unbalanced. Let us visualise it for the other classes to understand this better.<br>\nFor the \"Discount 5%\" here the \"1\" represents the condition when discount is given and \"0\" is when the discount is not given."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7af85e0d9631b12261c73c466345e9a452654601"
      },
      "cell_type": "code",
      "source": "sns.set_style(\"whitegrid\")\nsns.countplot(x='Discount 5%',data=train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "096b4510fe86938d7d2c6e6503fee50deeaef0b5"
      },
      "cell_type": "markdown",
      "source": "It seems that there are very few 5% discounts. Now let us view it for the 12% Discount."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7134b628d823f51f594f6220b25f3038f8ef6f00"
      },
      "cell_type": "code",
      "source": "sns.set_style(\"whitegrid\")\nsns.countplot(x='Discount 12%',data=train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0a0846da583f98fecb405f608dd77e402c014fa8"
      },
      "cell_type": "markdown",
      "source": "From this we can tell that the majority of the Discounts were 12%. Let us look at the 18% Discount."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "234d8ca629ca3bf7c1486951b0c2e1330c001539"
      },
      "cell_type": "code",
      "source": "sns.set_style(\"whitegrid\")\nsns.countplot(x='Discount 18%',data=train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2449b3c88fbd18d718a1438710d28c12f1279b48"
      },
      "cell_type": "markdown",
      "source": "Again we see the same pattern as in the 5% Discount but just a little more. Let us look at the final class i.e, 28% Discount."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1a5526094340ff16250d83cb1476dedfec87cc9"
      },
      "cell_type": "code",
      "source": "sns.set_style(\"whitegrid\")\nsns.countplot(x='Discount 28%',data=train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "21611be06f86186c733d88ff84a244e4bde66d53"
      },
      "cell_type": "markdown",
      "source": "We can see more discounts here and therefore is the second most occuring class after 12%. Since the class labels are so imbalanced we will be using SMOTE later on.<br><br>\n\nWe initially used the Customer variable but later on in our predictions we realised that it was actually degrading our model therefore we ended up not using it."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d180621d74dce063ae70edef150d37b9cc6224c3"
      },
      "cell_type": "code",
      "source": "#lol=df2[\"Customer\"].str.split(\", \",n=1,expand=True)\n#df2['CustomerName']=lol[0]\n#df2[\"Location\"]=lol[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "451e2a2dac6ddbae00d59841d8bfda150cf9095e"
      },
      "cell_type": "code",
      "source": "#lol1=df3[\"Customer\"].str.split(\", \",n=1,expand=True)\n#df3['CustomerName']=lol1[0]\n#df3[\"Location\"]=lol1[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e083415de78235aa1350fac98bb4d7e571bc16e"
      },
      "cell_type": "code",
      "source": "#set(df3['Location']).difference(set(df2[\"Location\"]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c829f5d5898981cac181f597582c760131b8b802"
      },
      "cell_type": "code",
      "source": "#df3[df3[\"Location\"]=='T.M.M. HOSPITAL, THIRUVALLA.']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f1db277c18bf4a057e108d5f78723cd6c98283c6"
      },
      "cell_type": "code",
      "source": "#sns.countplot(x=\"discount\",hue=\"Location\",data=df3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18492a4f472a39623b9197ddcce36df29fc0254e"
      },
      "cell_type": "code",
      "source": "#df2[\"discount\"].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28766dab64e1fb8d79c1663663f696f9abb96980"
      },
      "cell_type": "code",
      "source": "#len(set(trailtest['Customer']).difference(set(trailtrain['Customer'])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f582dc2e0b5b39ed0f7fc3f6a787e92924a88d8d"
      },
      "cell_type": "markdown",
      "source": "Now we will create a function that will combine all the class labels into one Target variable."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d8278fc83a9ae0bb7996a1fab6df2d08e9606b7"
      },
      "cell_type": "code",
      "source": "discount=[]\nfor i, row in train.iterrows():\n    if row[\"Discount 5%\"]==1.0:\n        discount.append(1)\n    elif row[\"Discount 12%\"]==1.0:\n        discount.append(2)\n    elif row[\"Discount 18%\"]==1.0:\n        discount.append(3)\n    elif row[\"Discount 28%\"]==1.0:\n        discount.append(4)\n    else:\n        discount.append(5)        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2bac6fc29118829bf8cb8fc68a9b6c4ae9fe7ee8"
      },
      "cell_type": "code",
      "source": "train[\"discount\"]=discount",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "61d34264733651cb59578f1a44d4f4ba666fb1c3"
      },
      "cell_type": "markdown",
      "source": "Let us now plot the word count of \"Customer\" for each Discount Class."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76b05d7e5fd99ba855fd2ffaf0713228e1cd0cf0"
      },
      "cell_type": "code",
      "source": "from wordcloud import WordCloud, STOPWORDS\nfrom collections import defaultdict\ntrain1_df = train[train[\"discount\"]==1]\ntrain2_df = train[train[\"discount\"]==2]\ntrain3_df = train[train[\"discount\"]==3]\ntrain4_df = train[train[\"discount\"]==4]\ntrain5_df = train[train[\"discount\"]==5]\n\n## custom function for ngram generation ##\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n## custom function for horizontal bar chart ##\ndef horizontal_bar_chart(df, color):\n    trace = go.Bar(\n        y=df[\"word\"].values[::-1],\n        x=df[\"wordcount\"].values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n## Get the bar chart from sincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"Customer\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n\n## Get the bar chart from insincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"Customer\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n\nfreq_dict = defaultdict(int)\nfor sent in train3_df[\"Customer\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n\nfreq_dict = defaultdict(int)\nfor sent in train4_df[\"Customer\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace3 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n\nfreq_dict = defaultdict(int)\nfor sent in train5_df[\"Customer\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace4 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=2, vertical_spacing=0.04,\n                          subplot_titles=[\"Frequent words of Discount 5%\", \n                                          \"Frequent words of Discount 12%\",\n                                         \"Frequent words of Discount 18%\",\n                                         \"Frequent words of Discount 28%\",\"Frequent words of No Discount\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\nfig.append_trace(trace3, 2, 2)\nfig.append_trace(trace4, 3, 1)\n\nfig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\npy.iplot(fig, filename='word-plots')\n\n#plt.figure(figsize=(10,16))\n#sns.barplot(x=\"ngram_count\", y=\"ngram\", data=fd_sorted.loc[:50,:], color=\"b\")\n#plt.title(\"Frequent words for Insincere Questions\", fontsize=16)\n#plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a809e5a74ceb8b4d7c05f85de7a0e2aef909778e"
      },
      "cell_type": "markdown",
      "source": "From these plots we can see that not any customer was given an extra likelihood of discounts."
    },
    {
      "metadata": {
        "_uuid": "289171332f9a84fc8c70168f2c74c1fd82a8a4b0"
      },
      "cell_type": "markdown",
      "source": "Let us drop the Discount columns now."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c8ad2f5e48f2910abb39d895d6464cf61723801a"
      },
      "cell_type": "code",
      "source": "train.drop(['Discount 5%','Discount 12%','Discount 18%','Discount 28%'],axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d202d667cc103ed0a623ff99379f5b710181e7ec"
      },
      "cell_type": "markdown",
      "source": "Since to differentiate the Customer Basket is an NLP Problem we will be using CountVectoriser. It converts a collection of text documents to a matrix of token counts. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b237d170b10509e071c80a297e25b830f43ae0f"
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\ncv1 = CountVectorizer(max_features=500)\ny = cv1.fit_transform(df[\"Customer_Basket\"]).toarray()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7c851304a6c2592c7ae383b158b49c783f33c78"
      },
      "cell_type": "code",
      "source": "len(cv1.vocabulary_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98825be280028b07efa495eba6dd074aaa84e680"
      },
      "cell_type": "code",
      "source": "thirty= list(y)\nthirty1=pd.DataFrame(thirty)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1662172d5e4dc39189d58793c501bd2db560a2b0"
      },
      "cell_type": "code",
      "source": "final=pd.concat([df,thirty1],axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ce7c194c2efcd62774f722f65846ec5f2be52f0"
      },
      "cell_type": "code",
      "source": "finaltrain=pd.merge(train,final,on=\"BillNo\",how=\"inner\")\nfinaltest=pd.merge(test,final,on=\"BillNo\",how=\"inner\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c3bc285ab0c12c3ed1c235b783048399e196a98"
      },
      "cell_type": "code",
      "source": "finaltrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ddee0ef9497e017bfe8929b3045254636d2aa36"
      },
      "cell_type": "code",
      "source": "finaltest.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46c54590923451eedf4846bdd41b09eaa2088712"
      },
      "cell_type": "code",
      "source": "#df2=df2[df2[\"BillNo\"]!=float(0.0)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f7b7515ebe8a4a1616b51dbc53575971c9242f9"
      },
      "cell_type": "code",
      "source": "finaltrain.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)\nfinaltest.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03834143807410b0217bb3a74a76ad6fdc821fde"
      },
      "cell_type": "code",
      "source": "X=finaltrain.drop(\"discount\",axis=1)\ny=finaltrain[\"discount\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "693de996af59cf7a848563c2028d5cd48b1d35fc"
      },
      "cell_type": "markdown",
      "source": "We will be using SMOTE here to balance the classes. It achieves this by oversampling. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c217c78800b5f2b475c08aa3b0fa5e3f7be214b"
      },
      "cell_type": "code",
      "source": "from imblearn.over_sampling import SMOTE",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f87a58c485d986f503c72b89a995d494eb5587a"
      },
      "cell_type": "code",
      "source": "sm = SMOTE(random_state=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0edda62e1e854f5a3855a79a9c55c2153cc0a699"
      },
      "cell_type": "code",
      "source": "X_train_res, y_train_res = sm.fit_sample(X, y.ravel())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c8fb8e0bc890e0bf1533b52ccbf0eec748db0ff"
      },
      "cell_type": "code",
      "source": "X_train=pd.DataFrame(X_train_res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "965410218fd5f03496351ab2da80c437955134c5"
      },
      "cell_type": "code",
      "source": "y_train=pd.DataFrame(y_train_res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01fe7ea8d064854b7d4dc6a13a34f7d1afecc345"
      },
      "cell_type": "code",
      "source": "X_train[\"smote\"]=y_train_res",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12999c254e8d98eaf32ca50b584eceab14d0dfac"
      },
      "cell_type": "code",
      "source": "X1=X_train.drop([\"smote\"],axis=1)\ny1=X_train[\"smote\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b16fdac65be2de4c89aa58d882b96757d33ffd3e"
      },
      "cell_type": "markdown",
      "source": "<font size=\"18\">Modeling</font>"
    },
    {
      "metadata": {
        "_uuid": "0b3e6304744a7fbce1e421dec33fe6fe53e8784f"
      },
      "cell_type": "markdown",
      "source": "This is the modeling section of our notebook we will be using various machine learning models to perform our predictions. We have performed the submission file creation only for one of the models but did implement it for the rest of the models."
    },
    {
      "metadata": {
        "_uuid": "214572eb37f56cbfda569b466fe5399c412571aa"
      },
      "cell_type": "markdown",
      "source": "<h1>Cross Validation for Hyperparameter tuning LightGBM</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7368fcc76bb79b3b11852f95a3b6f9f95c842376"
      },
      "cell_type": "code",
      "source": "params = {        \n    'learning_rate': [0.005],\n    'n_estimators': [200, 400, 600, 1000, 1800, 2000],\n    'num_leaves': [6,8,12,16],\n    'boosting_type' : ['gbdt'],\n    'objective' : 'multiclass',\n    'random_state' : [501],\n    'colsample_bytree' : [0.65, 0.66],\n    'subsample' : [0.7,0.75],\n    'reg_alpha' : [1,1.2],\n    'reg_lambda' : [1,1.2,1.4],\n    }",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31bb64369dabb66e2d08f72cb1ffbf3b7e062be9"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import KFold",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1443a18abb9a0d8cb167e487944965b458e1bcee"
      },
      "cell_type": "code",
      "source": "folds = 5\nparam_comb = 5\n\nskf = KFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(lgb, param_distributions=params, n_iter=param_comb, scoring=rmsle, n_jobs=4, cv=skf.split(X,y), verbose=3, random_state=1001 )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a40eb0aad310c604c1f17c242fb386a1b5859953"
      },
      "cell_type": "markdown",
      "source": "<h1>1. LightGBM</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c2f46f98493ca02f7065719ea05ff0159022f1f"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "556055e670ad9955918c633e0817b18247f51912"
      },
      "cell_type": "code",
      "source": "model = lgb.LGBMClassifier( class_weight = 'balanced',\n                               objective = 'multiclass', n_jobs = -1, n_estimators = 500)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35836eaa23cbd5a5544c858a14153fb04e54c974"
      },
      "cell_type": "code",
      "source": "model.fit(X1,y1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e36dd1ee942dcd80f17cb97820949aea03a4727"
      },
      "cell_type": "code",
      "source": "pred_lg=model.predict(finaltest)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b619bb292786a4812aff381c68c8e041b4ffe3aa"
      },
      "cell_type": "code",
      "source": "pred_lg",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef432ae57da6c9099fa20783518121c2b8b637c6"
      },
      "cell_type": "markdown",
      "source": "<h1>Cross Validation for Hyperparameter tuning Random Forest</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60394daaa9549a39846d0e228c88cbb65624915b"
      },
      "cell_type": "code",
      "source": "params = {\n    'eta': 0.3,\n    'tree_method': \"hist\",\n    'grow_policy': \"lossguide\",\n    'max_leaves': 1000,  \n    'max_depth': 0, \n    'subsample': 0.9, \n    'alpha':1,\n    'objective': 'multi:softprob', \n    'scale_pos_weight':100,\n    'eval_metric': 'auc', \n    'nthread':4,\n    'silent': 1\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2083505935a6d79bfa1a954cd4cbdbf0c4668e39"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import KFold",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fadeeb449b983a8d66bd86ae8d8d3075ef820c78"
      },
      "cell_type": "code",
      "source": "folds = 5\nparam_comb = 5\n\nskf = KFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(rfc, param_distributions=params, n_iter=param_comb, scoring=rmsle, n_jobs=4, cv=skf.split(X,y), verbose=3, random_state=1001 )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d849d225b7d568b22e71c61b4dc1c63cf99046c6"
      },
      "cell_type": "markdown",
      "source": "<h1>2. XGBOOST</h1>"
    },
    {
      "metadata": {
        "_uuid": "b6c0bb3f4b7fd6120b59f847df3d4b264d543650"
      },
      "cell_type": "markdown",
      "source": "We commented the xgboost out becuase in the kernel it would show a long output on the kernel. The code definitely works for multiclass classification so you guys are free to run it."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15161cd7e83825fc7f967d747626bbec1941821e"
      },
      "cell_type": "code",
      "source": "import xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0878527d47a63181aff2a62d6ac9107103a0be9"
      },
      "cell_type": "code",
      "source": "xgb = XGBClassifier(max_depth=5, learning_rate=0.2, n_estimators=500,\n                    objective='multi:softprob', subsample=0.6, colsample_bytree=0.6, seed=0, silent=0)                  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "675ccf68882129a7350094bd0845a9586d8830e2"
      },
      "cell_type": "code",
      "source": "xgb.fit(X1, y1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "cb1d134df9b71b9091bc113079395159dbab1a17"
      },
      "cell_type": "code",
      "source": "pred_xg=xgb.predict(finaltest)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "61a69ec5cf50c3363dba124d5c5f53458bfa3634"
      },
      "cell_type": "markdown",
      "source": "<h1>Cross Validation for Hyperparameter tuning Random Forest</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f1e37b2bf59ebde4867434d5f7fc15d72f68164"
      },
      "cell_type": "code",
      "source": "params={'bootstrap': [True, False],\n 'max_depth': [10, 50, 80, 100, None],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 1000, 1800, 2000]}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bec9b8d54f808f3db62db768a9ed4003f0bd4535"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import KFold",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78cec1119b6da37c0f7467b5af85538f1a6c5057"
      },
      "cell_type": "code",
      "source": "folds = 5\nparam_comb = 5\n\nskf = KFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(rfc, param_distributions=params, n_iter=param_comb, scoring=rmsle, n_jobs=4, cv=skf.split(X,y), verbose=3, random_state=1001 )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5f79ed7600410f75177d96a010832d2b6118517"
      },
      "cell_type": "code",
      "source": "random_search.fit(X, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c29afb15040b1fae529f823da4e3cd3e167953c1"
      },
      "cell_type": "code",
      "source": "print('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a2dee548498434e410fd09901cce16aa2351f5f"
      },
      "cell_type": "markdown",
      "source": "<h1>3.Random Forest Classifier</h1>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "576589b4bdaa55dca6bbfe504db975572266b927"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4cc8d5b0c0a335ec932745969547d62561242be1"
      },
      "cell_type": "code",
      "source": "rfc=RandomForestClassifier(n_estimators=500)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb631a9f798ca8c735c95959ec9e65b29775a572"
      },
      "cell_type": "code",
      "source": "rfc.fit(X1,y1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26041905d22c03424265ae99be64786b3e6b6b66"
      },
      "cell_type": "code",
      "source": "rfcpredict=rfc.predict(finaltest)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7041f1259a3e3ea7fa9793ec5e53e3a0a2ff5858"
      },
      "cell_type": "code",
      "source": "rfcpredict",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "63c331ef66f1b78fed8651c390f83da599530d42"
      },
      "cell_type": "markdown",
      "source": "<h1>Result</h1>"
    },
    {
      "metadata": {
        "_uuid": "00ca9f445216b1386d4cd4d9eef9c88600e62b97"
      },
      "cell_type": "markdown",
      "source": "At the end we were able to discern that LightGBM gave us the best results and that was what we submitted finally."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}